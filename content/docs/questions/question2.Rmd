# What student information helps predict success in their courses?

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment='', warning = FALSE)
```

## Set up and load data

```{r}
rm(list =ls())
library(pacman)
p_load(tidyverse, broom, ggplot2, kableExtra, interactions)
load("D:/R/data analysis/Institutional research/technical-exercise/content/docs/questions/data_230214_1659.Rdata")
```

## Research question
**What student information helps predict success in their courses?**

Success in course can be found in the **course_enrollments** data set and be defined as C or better score in their official grade.

The student information can be obtained from **student_details** data set, which include information like **student_id_number**, **ACT_score**, **hs_gpa_entry**, and **hardship_score**. 

## Data cleaning
I conduct following steps to clean data:
1. Combine **student_details** and **course_enrollments** data set via student_id_number variable.
2. Deal with missing values and extreme values

```{r warning=FALSE}
DF <- student_details %>%
  full_join(course_enrollments, by="student_id_number") %>%
  select(c("student_id_number","ACT_score","hs_gpa_entry","hardship_score","success"))
```

```{r echo=FALSE}
summary(DF)
```
### Deal with missing values and extreme values
After summarizing the **DF** data set, we can find there are extreme values in **hs_gpa_entry** (e.g., it has 533), and missing values in several variables (**ACT_score**, **hs_gpa_entry**, and **success**).

1. Extreme values

For extreme values in **hs_gpa_entry**, I record them as NA since I do not have information about how the data are collected.
```{r}
DF <- DF %>%
  mutate(
    hs_gpa_entry = case_when(
      hs_gpa_entry <= 5 ~hs_gpa_entry, 
      TRUE ~ NA
    )
  )
```

2. Missing values

After combining two data sets, the new data set: **DF** has several variables (**ACT_score**, **hs_gpa_entry**, and **success**) with missing values, which might caused by joining two data sets. **student_details** data set has some students that are not included in the **course_enrollments** data set. 
I first examine the **course_enrollments** data set to see whether it has missing value.

```{r include=FALSE}
course_enrollments$official_grade <- as.factor(course_enrollments$official_grade)
```

```{r}
summary(course_enrollments)
```
All students in this data set has official grades. So, in the joined data set **DF**, I drop those observations without official grades (i.e. NA in **success** variable).

```{r}
DF <- DF %>%
  filter(!is.na(success))
```

## Visualization
Through visualization, I plan to examine difference on ACT_score, hs_gpa_entry, and hardship_score between the groups of students who have C or better and others.
-   ACT_score

```{r}
DF %>%
  ggplot(aes(x = success, y = ACT_score)) +
  geom_boxplot()+
  labs(
    x = "Success",
    y = "ACT score",
    title = ""
  ) +
  theme_classic()
```

-   hs_gpa_entry

```{r}
DF %>%
  ggplot(aes(x = success, y = hs_gpa_entry)) +
  geom_boxplot()+
  labs(
    x = "Success",
    y = "HS GPA entry",
    title = ""
  ) +
  theme_classic()

```

-   hardship_score

```{r}
DF %>%
  ggplot(aes(x = success, y = hardship_score)) +
  geom_boxplot()+
  labs(
    x = "Success",
    y = "Hardship score",
    title = ""
  ) +
  theme_classic()
```

Three box plots do not show huge differences on ACT_score, hs_gpa_entry, and hardship_score between students succeed and others.

Next, I conduct logistic regression to examine how those three variables predict student success rates.

## Logistic regression
1. Run basic logistic regression model
2. Evaluate interactions
3. Run model with interactions
4. Compare two models



### Basic Model
First, I run the basic logistic regression model with three independent variables (**ACT_score**, **hs_gpa_entry**,**hardship_score**) without considering interaction.

```{r}
DF$success <- relevel((DF$success), ref = "N")
```

```{r}
formula <- as.formula(success~ ACT_score+ hs_gpa_entry+ hardship_score)
lr <- glm(formula, data = DF, family = binomial(link = "logit"))
```

When we interpret the results, we look at the odds ratio.

-   Odds ratio is an measure of association between dependent variable and independent variables in the logistic regression. It estimates the change in the odd of membership in the target group for one unit increase in the predictor.

-  Odds ratio > 1 indicates the condition or event is more likely to occur in the first group. In our case, it means positive relationship between the odds of succeed and several variables related to student information. 

-  Odds ratio < 1 indicates that the condition or event is less likely to occur in the first group, which refers negative relationship between the odds of succeed and several variables related to student information. 

```{r warning=FALSE}
broom::tidy(lr, exp = TRUE) %>%
  kable(
    col.names = c("Term","Odds ratio","Standard error","Z value", "P value")
  ) %>% 
  kable_styling("basic", bootstrap_options = "striped", full_width = F, position = "left")
```

The results show that all three independent variables are statistically significant associated with the dependent variable (**success**).

-   ACT_score: After controlling all other variables, the odds of succeed **decrease** as ACT score increases.

-   hs_gpa_entry: After controlling all other variables, the odds of succeed **increase** as hs_gpa_entry increases.

-   hardship_score: After controlling all other variables, the odds of succeed **decrease** as hardship score increases.

### Add Interactions

Intuitively, those three variables might interact with each other when predicting **success** variable. To verify it, I first examine the interactions. Next, based on the results, I choose the interactions to add in the model.

<details><summary>Evaluate interactions</summary>

-   ACT_score*hardship_score

```{r warning= FALSE}
formulaAH <- as.formula(success~ ACT_score+ hs_gpa_entry+ hardship_score + ACT_score*hardship_score)
lrAH <- glm(formulaAH, data = DF, family = binomial(link = "logit"))
sim_slopes(lrAH, pred = ACT_score, modx = hardship_score, johnson_neyman = TRUE, jnplot = TRUE)
```

From the plot, we can see that for ACT_score, the slope of hardship_score is significantly different from zero and in this case negative.

-   hs_gpa_entry*hardship_score

```{r warning=FALSE}
formulaHH <- as.formula(success~ ACT_score+ hs_gpa_entry+ hardship_score + hs_gpa_entry*hardship_score)
lrHH <- glm(formulaHH, data = DF, family = binomial(link = "logit"))
sim_slopes(lrHH, pred = hs_gpa_entry, modx = hardship_score, johnson_neyman = TRUE, jnplot = TRUE)
```

For hs_gpa_entry, the slope of hardship_score is also significantly different from zero and positive. 

Overall, those two interactions are significant. So, I include these interactions and compare the new model with the previous basic model.
</details>


<details><summary>Run model with interactions</summary>

```{r}
formulaFull<- as.formula(success~ ACT_score+ hs_gpa_entry+ hardship_score + ACT_score*hardship_score + hs_gpa_entry*hardship_score)
lrFull <- glm(formulaFull, data = DF, family = binomial(link = "logit"))
```


```{r warning=FALSE}
broom::tidy(lrFull, exp = TRUE) %>%
  kable(
    col.names = c("Term","Odds ratio","Standard error","Z value", "P value")
  ) %>% 
  kable_styling("basic", bootstrap_options = "striped", full_width = F, position = "left")
```
</details>

All interaction terms do not statistically significant, but I still want to compare those two models and see which one performs better.


### Compare two models

To choose from those two models, I compare several criteria of them. One is AIC, which is a commonly used measurement to compare models; lower values are considered better fitting than those with larger values.

Another is pseudo R-square, which provides model fit information. 

-   AIC

```{r}
glance(lr)
glance(lrFull)
```

Those two tables show that the basic model has smaller AIC (20748.94) than the model with interactions (AIC = 20749.79).

-   Pseudo R-Square

```{r}
DescTools::PseudoR2(lr, which =  "all")
DescTools::PseudoR2(lrFull, which =  "all")
```

Results of pseudo R-square tables show that the basic model accounts for approximately 23.95% of the total variance; the model with interactions accounts for approximately 24.21% of the total variance, slightly higher than basic model.

## Conclusion

In summary, while the interaction models have slightly higher pseudo R-square, considering significance of coefficients and AIC, I choose the basic model.

Variables (**ACT_score**, **hs_gpa_entry**, **hardship_score**) significantly predict success. 

Higher ACT score and higher hardship score are associated with lower success rates; Higher high school GPA entry are associated with higher success rates.
